{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-3b7df5b51e37>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\student\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\student\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\student\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\student\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\student\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#대표적 Unsupervised learning\n",
    "#Generator->가짜 이미지를 만들어 내는 역할 (실제 데이터 분포와 유사한 데이터 분포를 만들어 내는 것이 역할)\n",
    "#Discriminator-> 진짜일수록 1에 가까운 이미지\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps=10000\n",
    "batch_size=128\n",
    "learning_rate=0.0002\n",
    "#G,D-DNN{256 hidden nodes}\n",
    "image_dim=784\n",
    "gen_hidden_dim=256\n",
    "disc_hidden_dim=256\n",
    "noise_dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_init(shape):\n",
    "    return tf.random_normal(shape=shape,stddev=1./tf.sqrt(shape[0]/2))\n",
    "weights ={\n",
    "    'gen_hidden1':tf.Variable(he_init([noise_dim,gen_hidden_dim])),\n",
    "    'gen_out':tf.Variable(he_init([gen_hidden_dim,image_dim])),\n",
    "    'disc_hidden1':tf.Variable(he_init([image_dim,disc_hidden_dim])),\n",
    "    'disc_out':tf.Variable(he_init([disc_hidden_dim,1]))\n",
    "}\n",
    "biased= {\n",
    "    'gen_hidden1':tf.Variable(tf.zeros([gen_hidden_dim])),\n",
    "    'gen_out':tf.Variable(tf.zeros([image_dim])),\n",
    "    'disc_hidden1':tf.Variable(tf.zeros([disc_hidden_dim])),\n",
    "    'disc_out':tf.Variable(tf.zeros([1]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x):\n",
    "    hidden_layer = tf.matmul(x,weights['gen_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer,biased['gen_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    output_layer = tf.matmul(hidden_layer,weights['gen_out'])\n",
    "    output_layer = tf.add(output_layer,biased['gen_out'])\n",
    "    output_layer = tf.nn.sigmoid(output_layer)\n",
    "    return output_layer\n",
    "\n",
    "def discriminator(x):\n",
    "    hidden_layer = tf.matmul(x,weights['disc_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer,biased['disc_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    output_layer = tf.matmul(hidden_layer,weights['disc_out'])\n",
    "    output_layer = tf.add(output_layer,biased['disc_out'])\n",
    "    output_layer = tf.nn.sigmoid(output_layer)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input=tf.placeholder(tf.float32,shape=[None,noise_dim],name='input_noise')\n",
    "disc_input=tf.placeholder(tf.float32,shape=[None,image_dim],name='disc_input')\n",
    "\n",
    "gen_sample=generator(gen_input)\n",
    "disc_real = discriminator(disc_input)\n",
    "disc_fake = discriminator(gen_sample)\n",
    "\n",
    "gen_loss= -tf.reduce_mean(tf.log(disc_fake))\n",
    "\n",
    "disc_loss = -tf.reduce_mean(tf.log(disc_real)+tf.log(1-disc_fake))#log(D(x))+log(1-D(G(x)))\n",
    "\n",
    "optimizer_gen=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "gen_var=[weights['gen_hidden1'],weights['gen_out'],biased['gen_hidden1'],biased['gen_out']]\n",
    "disc_var=[weights['disc_hidden1'],weights['disc_out'],biased['disc_hidden1'],biased['disc_out']]\n",
    "train_gen=optimizer_gen.minimize(gen_loss,var_list=gen_var)\n",
    "train_disc=optimizer_disc.minimize(disc_loss,var_list=disc_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 G Loss:  0.51023096 D loss:  1.6910877\n",
      "Step:  100 G Loss:  4.304199 D loss:  0.0562232\n",
      "Step:  200 G Loss:  3.4847608 D loss:  0.16653407\n",
      "Step:  300 G Loss:  2.6270256 D loss:  0.29272982\n",
      "Step:  400 G Loss:  2.9421144 D loss:  0.18517986\n",
      "Step:  500 G Loss:  3.1210232 D loss:  0.1304935\n",
      "Step:  600 G Loss:  3.401279 D loss:  0.10034922\n",
      "Step:  700 G Loss:  3.4512744 D loss:  0.07740161\n",
      "Step:  800 G Loss:  3.5192213 D loss:  0.07086007\n",
      "Step:  900 G Loss:  3.745284 D loss:  0.048982583\n",
      "Step:  1000 G Loss:  3.7151065 D loss:  0.06478716\n",
      "Step:  1100 G Loss:  3.804489 D loss:  0.057835408\n",
      "Step:  1200 G Loss:  3.7682762 D loss:  0.10274626\n",
      "Step:  1300 G Loss:  3.7630925 D loss:  0.08882432\n",
      "Step:  1400 G Loss:  3.7492514 D loss:  0.06193714\n",
      "Step:  1500 G Loss:  3.9610198 D loss:  0.08357944\n",
      "Step:  1600 G Loss:  4.0925045 D loss:  0.06417206\n",
      "Step:  1700 G Loss:  3.8507118 D loss:  0.055582985\n",
      "Step:  1800 G Loss:  4.8300495 D loss:  0.06652072\n",
      "Step:  1900 G Loss:  4.4171267 D loss:  0.047066607\n",
      "Step:  2000 G Loss:  4.5955486 D loss:  0.06402801\n",
      "Step:  2100 G Loss:  4.8514977 D loss:  0.028015634\n",
      "Step:  2200 G Loss:  4.9764085 D loss:  0.038730677\n",
      "Step:  2300 G Loss:  5.7097235 D loss:  0.01392468\n",
      "Step:  2400 G Loss:  5.257229 D loss:  0.029884236\n",
      "Step:  2500 G Loss:  5.1390114 D loss:  0.018302085\n",
      "Step:  2600 G Loss:  5.3303127 D loss:  0.011385028\n",
      "Step:  2700 G Loss:  5.3693447 D loss:  0.023193117\n",
      "Step:  2800 G Loss:  5.228758 D loss:  0.02163381\n",
      "Step:  2900 G Loss:  5.7445374 D loss:  0.0143867545\n",
      "Step:  3000 G Loss:  5.8492613 D loss:  0.011656756\n",
      "Step:  3100 G Loss:  5.5540104 D loss:  0.02129209\n",
      "Step:  3200 G Loss:  5.156965 D loss:  0.012780034\n",
      "Step:  3300 G Loss:  4.61903 D loss:  0.021413352\n",
      "Step:  3400 G Loss:  4.2796507 D loss:  0.035798945\n",
      "Step:  3500 G Loss:  3.4572315 D loss:  0.08793233\n",
      "Step:  3600 G Loss:  3.3333519 D loss:  0.08897528\n",
      "Step:  3700 G Loss:  3.52843 D loss:  0.06986707\n",
      "Step:  3800 G Loss:  3.4916277 D loss:  0.05493537\n",
      "Step:  3900 G Loss:  4.2921457 D loss:  0.059116036\n",
      "Step:  4000 G Loss:  4.161047 D loss:  0.047426984\n",
      "Step:  4100 G Loss:  4.464784 D loss:  0.03146299\n",
      "Step:  4200 G Loss:  4.4978905 D loss:  0.032428913\n",
      "Step:  4300 G Loss:  4.7047834 D loss:  0.12005363\n",
      "Step:  4400 G Loss:  4.0720444 D loss:  0.07254492\n",
      "Step:  4500 G Loss:  3.8410447 D loss:  0.0774199\n",
      "Step:  4600 G Loss:  4.2150965 D loss:  0.06763815\n",
      "Step:  4700 G Loss:  3.8911395 D loss:  0.0951491\n",
      "Step:  4800 G Loss:  4.3641396 D loss:  0.080234826\n",
      "Step:  4900 G Loss:  4.49617 D loss:  0.099938\n",
      "Step:  5000 G Loss:  4.2873473 D loss:  0.12665588\n",
      "Step:  5100 G Loss:  3.7221596 D loss:  0.14511977\n",
      "Step:  5200 G Loss:  4.0638814 D loss:  0.08662843\n",
      "Step:  5300 G Loss:  4.418788 D loss:  0.06452235\n",
      "Step:  5400 G Loss:  4.461584 D loss:  0.10220386\n",
      "Step:  5500 G Loss:  4.2036266 D loss:  0.086284205\n",
      "Step:  5600 G Loss:  4.152717 D loss:  0.07014569\n",
      "Step:  5700 G Loss:  4.7153416 D loss:  0.12349023\n",
      "Step:  5800 G Loss:  4.458871 D loss:  0.10680276\n",
      "Step:  5900 G Loss:  4.158992 D loss:  0.12317936\n",
      "Step:  6000 G Loss:  4.404538 D loss:  0.08780287\n",
      "Step:  6100 G Loss:  3.856491 D loss:  0.1526983\n",
      "Step:  6200 G Loss:  4.023542 D loss:  0.14043131\n",
      "Step:  6300 G Loss:  4.0614195 D loss:  0.11471345\n",
      "Step:  6400 G Loss:  4.0671673 D loss:  0.10661147\n",
      "Step:  6500 G Loss:  4.0373197 D loss:  0.071276195\n",
      "Step:  6600 G Loss:  3.7318144 D loss:  0.12444447\n",
      "Step:  6700 G Loss:  4.1024623 D loss:  0.106027186\n",
      "Step:  6800 G Loss:  3.804171 D loss:  0.13467517\n",
      "Step:  6900 G Loss:  4.285782 D loss:  0.07608443\n",
      "Step:  7000 G Loss:  3.9259636 D loss:  0.11285128\n",
      "Step:  7100 G Loss:  3.7927585 D loss:  0.13885763\n",
      "Step:  7200 G Loss:  4.0415773 D loss:  0.079994634\n",
      "Step:  7300 G Loss:  3.9904964 D loss:  0.1421937\n",
      "Step:  7400 G Loss:  3.532302 D loss:  0.16041079\n",
      "Step:  7500 G Loss:  4.024686 D loss:  0.15441462\n",
      "Step:  7600 G Loss:  4.008392 D loss:  0.14160424\n",
      "Step:  7700 G Loss:  3.990021 D loss:  0.18535627\n",
      "Step:  7800 G Loss:  3.7502012 D loss:  0.166649\n",
      "Step:  7900 G Loss:  4.1267786 D loss:  0.115994096\n",
      "Step:  8000 G Loss:  3.8481877 D loss:  0.1437199\n",
      "Step:  8100 G Loss:  3.7815263 D loss:  0.15272605\n",
      "Step:  8200 G Loss:  4.20269 D loss:  0.14540035\n",
      "Step:  8300 G Loss:  3.285716 D loss:  0.17693135\n",
      "Step:  8400 G Loss:  3.9840417 D loss:  0.13063431\n",
      "Step:  8500 G Loss:  3.936728 D loss:  0.15596431\n",
      "Step:  8600 G Loss:  4.151739 D loss:  0.1428453\n",
      "Step:  8700 G Loss:  4.013971 D loss:  0.17071739\n",
      "Step:  8800 G Loss:  3.8432026 D loss:  0.16139051\n",
      "Step:  8900 G Loss:  3.7720582 D loss:  0.18519834\n",
      "Step:  9000 G Loss:  3.9640882 D loss:  0.11369233\n",
      "Step:  9100 G Loss:  4.071808 D loss:  0.12610063\n",
      "Step:  9200 G Loss:  3.8955226 D loss:  0.1412836\n",
      "Step:  9300 G Loss:  3.878423 D loss:  0.16021904\n",
      "Step:  9400 G Loss:  4.0146313 D loss:  0.13101101\n",
      "Step:  9500 G Loss:  4.003449 D loss:  0.12813321\n",
      "Step:  9600 G Loss:  4.250807 D loss:  0.11903239\n",
      "Step:  9700 G Loss:  4.177986 D loss:  0.13409722\n",
      "Step:  9800 G Loss:  4.2339134 D loss:  0.15024987\n",
      "Step:  9900 G Loss:  4.3107624 D loss:  0.13652772\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(num_steps):\n",
    "    batch_xs,_=mnist.train.next_batch(batch_size)\n",
    "    z=np.random.uniform(-1.,1.,size=[batch_size,noise_dim])\n",
    "    _,_,gl,dl=sess.run([train_gen,train_disc,gen_loss,disc_loss],feed_dict={disc_input:batch_xs,gen_input:z})\n",
    "    if i%100==0:\n",
    "        print('Step: ',i,'G Loss: ',gl,'D loss: ',dl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
